# <div align="center">Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024</div>

<div align="center">  <a href="https://arxiv.org/abs/2503.02857">Paper</a> | <a href="https://huggingface.co/datasets/nuriachandra/Deepfake-Eval-2024">Dataset</a></div>

### Examples of Deepfake-Eval-2024
![Examples of Deepfake-Eval-2024 video and audio (rows 1–2), and images (rows 3–4),
demonstrating a diversity of content styles and generation techniques, including lipsync, faceswap, and diffusion. Images have been resized for presentation.](assets/fig1_examples.png)

Deepfake-Eval-2024 is an in-the-wild deepfake dataset. Deepfake-Eval-2024 contains 44 hours of videos, 56.5 hours of audio, and 1,975 images, encompassing contemporary manipulation technologies, diverse media content, 88 different website sources, and 52 different languages. Deepfake-Eval-2024 contains manually labeled real and fake media. 

## Citation
`@misc{chandra2025deepfakeeval2024multimodalinthewildbenchmark,
      title={Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024}, 
      author={Nuria Alina Chandra and Ryan Murtfeldt and Lin Qiu and Arnab Karmakar and Hannah Lee and Emmanuel Tanumihardja and Kevin Farhat and Ben Caffee and Sejin Paik and Changyeon Lee and Jongwook Choi and Aerin Kim and Oren Etzioni},
      year={2025},
      eprint={2503.02857},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2503.02857}, 
}`